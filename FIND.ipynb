{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   This section of the code simply sets up all possible variables we might want to change during training.\n",
    "\"\"\"\n",
    "import os, sys, random, gzip, optparse\n",
    "import numpy as np                     # Math and Deep Learning libraries\n",
    "import torch                \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm                  # Pretty status bars\n",
    "from collections import defaultdict\n",
    "np.seterr(divide='ignore')             # Ignore divide by zero errors\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "# Use a GPU when possible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "parser = optparse.OptionParser(description='FIND')\n",
    "parser.add_option('--name',       type=str,            default='')\n",
    "parser.add_option('--batch-size', type=int,            default=32,    help='batch size')\n",
    "parser.add_option('--epochs',     type=int,            default=100,   help='number of epochs')\n",
    "parser.add_option('--hidden-dim', type=int,            default=256,   help='hidden dim')\n",
    "parser.add_option('--log',        type=str,            default='./logs/')\n",
    "parser.add_option('--load',       type=str,            default='',    help='Load model')\n",
    "parser.add_option('--load_test',  type=str,            default='',    help='Load specific test file')\n",
    "parser.add_option('--binary',     type=str,            default='',    help='Binary classifer based on argument')\n",
    "parser.add_option('--lr',         type=float,          default=5e-3)\n",
    "parser.add_option('--nitro',      action='store_true', default=False, help='Train/Test on nitrogenase')\n",
    "parser.add_option('--bd',         action='store_true', default=False, help='Train/Test on cytochrome bd oxidase')\n",
    "parser.add_option('--test',       action='store_true', default=False, help='Swap validation for test set')\n",
    "parser.add_option('--confusion',  action='store_true', default=False, help='If test, generate confusion matrix')\n",
    "parser.add_option('--pconfusion', action='store_true', default=False, help='sum probabilities for confusion')\n",
    "parser.add_option('--reweight',   action='store_true', default=False)\n",
    "\n",
    "\n",
    "sys.argv = sys.argv[3:]  # Remove pykernel launcher\n",
    "args, _ = parser.parse_args()\n",
    "\n",
    "# BD is small with highly varying lengths so we shrink batch and therefore learning rate\n",
    "# Example run below\n",
    "args.bd = True\n",
    "args.batch_size = 4\n",
    "args.lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##    Infrastructure to process Data into Numpy Arrays of Integers\n",
    "##    Here we specify the dataset (indicated by args.nitro, args.bd or default HCO)\n",
    "##    Then we convert letters to numbers via the acids dictionary.\n",
    "##    We also compute the set of function labels (optionally training with binary)\n",
    "###############################################################################\n",
    "DATA_DIR = \"data/\"\n",
    "acids = {' ':0, 'A':1, 'C':2, 'E':3, 'D':4, 'G':5, 'F':6, 'I':7, 'H':8, \\\n",
    "         'K':9, 'M':10, 'L':11, 'N':12, 'Q':13, 'P':14, 'S':15, 'R':16, \\\n",
    "         'T':17, 'W':18, 'V':19, 'Y':20, 'X':21 }\n",
    "ints = {}\n",
    "for v in acids:\n",
    "    ints[acids[v]] = v\n",
    "\n",
    "lbls = {}\n",
    "ilbls = {}\n",
    "\n",
    "if args.nitro:\n",
    "    labels_file = \"nitro.labels.txt\"\n",
    "elif args.bd:\n",
    "    labels_file = \"bd.labels.txt\"\n",
    "else:\n",
    "    labels_file = \"hco.labels.txt\"\n",
    "\n",
    "L = [line.strip() for line in open(DATA_DIR + labels_file,'r')]\n",
    "# For logging we will store details of our training regime in the file name\n",
    "run = \"binary\" if args.binary else \"multi\"\n",
    "run += \".e{}\".format(args.epochs)\n",
    "run += \".h{}\".format(args.hidden_dim)\n",
    "run += \".b{}\".format(args.batch_size)\n",
    "if args.reweight:\n",
    "    run += \".reweight\"\n",
    "\n",
    "if len(args.binary) == 0:\n",
    "    for v in L:\n",
    "        lbls[v] = len(lbls)\n",
    "        ilbls[lbls[v]] = v\n",
    "    num_labels = len(lbls)\n",
    "else:\n",
    "    for v in L:\n",
    "        if v == args.binary:\n",
    "            lbls[v] = 1\n",
    "            ilbls[lbls[v]] = v\n",
    "        else:\n",
    "            lbls[v] = 0\n",
    "            ilbls[lbls[v]] = \"OTHER\"\n",
    "    print(lbls, ilbls)\n",
    "    num_labels = 2\n",
    "    run += \".\" + args.binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##    This block introduces helper functions\n",
    "##    to_int and to_string convert AAs back and forth between representations\n",
    "##    sort_data and pad_data help create batches of data of a fixed length to pass\n",
    "##      to the network.\n",
    "###############################################################################\n",
    "\n",
    "def to_int(seq):\n",
    "    \"\"\"   Map AA sequence to integers  \"\"\"\n",
    "    seq = seq.replace(\"*\",\"\")\n",
    "    conv = []\n",
    "    for i in range(len(seq)):\n",
    "        if seq[i] not in acids:\n",
    "            print(i, seq)\n",
    "        conv.append(acids[seq[i]])\n",
    "    return np.array(conv)\n",
    "\n",
    "def to_string(seq):\n",
    "    \"\"\"  Map ints to AA sequence  \"\"\"\n",
    "    return \"\".join([ints[s] for s in seq])\n",
    "\n",
    "def sort_data(inputs, outputs, strs=[]):\n",
    "    \"\"\" \n",
    "      Sorted by input length and then output length\n",
    "    \"\"\"\n",
    "    ignore_strs = False\n",
    "    if len(strs) == 0:\n",
    "        ignore_strs = True\n",
    "        strs = [\"\"]*len(inputs)\n",
    "    v = []\n",
    "    for i, o, s in zip(inputs, outputs, strs):\n",
    "        v.append((len(i), i, o, s))\n",
    "    v.sort(key=lambda x: x[0])\n",
    "\n",
    "    sorted_inputs = []\n",
    "    sorted_outputs = []\n",
    "    sorted_strs= []\n",
    "    for len_i, i, o, s in v:\n",
    "        sorted_inputs.append(i)\n",
    "        sorted_outputs.append(o)\n",
    "        sorted_strs.append(s)\n",
    "\n",
    "    if ignore_strs:\n",
    "        return sorted_inputs, sorted_outputs\n",
    "    else:\n",
    "        return sorted_inputs, sorted_outputs, sorted_strs\n",
    "\n",
    "def pad_data(inputs):\n",
    "    max_i = max([len(i) for i in inputs])\n",
    "  \n",
    "    padded_i = np.zeros((len(inputs), max_i), dtype=np.int64)\n",
    "    for i in range(len(inputs)):\n",
    "        padded_i[i, :len(inputs[i])] = np.copy(inputs[i])\n",
    "\n",
    "    return padded_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training counts\t\n",
      "E1: 381    C: 196    E2: 191    A: 50    E4: 40    E3: 30    B: 29\n",
      "Train Inps:  917\n",
      "Train Outs:  (917,)\n",
      "Test  Inps:  126\n",
      "Test  Outs:  (126,)\n",
      "Labels\t {'E4': 0, 'C': 1, 'E1': 2, 'A': 3, 'E2': 4, 'B': 5, 'E3': 6}\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "##    Data is loaded, Train/Validation/Test, counted, converted to numbers and \n",
    "##    stored in numpy arrays.\n",
    "###############################################################################\n",
    "\"\"\" Data & Parameters \"\"\"\n",
    "if args.nitro:\n",
    "    prefix = \"nitro.labeled\" \n",
    "elif args.bd:\n",
    "    prefix = \"bd.labeled\"\n",
    "else:\n",
    "    prefix = \"hco.labeled\"\n",
    "\n",
    "data = [line.strip().split() for line in open(DATA_DIR + prefix + \".train\",'r')]\n",
    "if args.test:\n",
    "    val = [line.strip().split() for line in open(DATA_DIR + prefix + \".test\",'r')]\n",
    "elif args.load_test != '':\n",
    "    val = [line.strip().split() for line in open(args.load_test,'r')]\n",
    "else:\n",
    "    val = [line.strip().split() for line in open(DATA_DIR + prefix + \".val\",'r')]\n",
    "\n",
    "for vals in data:\n",
    "    if len(vals) != 2:\n",
    "        print(vals)\n",
    "strs = np.array([sequence for label, sequence in data])\n",
    "inputs = [to_int(sequence) for label, sequence in data]\n",
    "outputs = np.array([lbls[label] for label, sequence in data])\n",
    "\n",
    "print(\"Training counts\\t\")\n",
    "l_c = defaultdict(int) \n",
    "for v in outputs:\n",
    "    l_c[ilbls[v]] += 1\n",
    "V = [(l_c[v],v) for v in l_c]\n",
    "V.sort()\n",
    "V.reverse()\n",
    "print(\"    \".join([\"{}: {}\".format(lbl, cnt) for cnt,lbl in V]))\n",
    "\n",
    "count = np.zeros(len(ilbls), dtype=np.float32)\n",
    "\n",
    "for v in range(len(ilbls)):\n",
    "    if ilbls[v] in l_c:\n",
    "        count[v] += l_c[ilbls[v]]\n",
    "distr = np.sum(count)/(np.size(count)*count) #1. - count/np.sum(count)\n",
    "weight = torch.from_numpy(100*distr).to(device)\n",
    "\n",
    "inps, outs, strs = sort_data(inputs, outputs, strs)\n",
    "outs = np.array(outs)\n",
    "strs = np.array(strs)\n",
    "\n",
    "t_strs = np.array([sequence for label, sequence in val])\n",
    "t_inps = [to_int(sequence) for label, sequence in val]\n",
    "t_outs = np.array([lbls[label] for label, sequence in val])\n",
    "t_inps, t_outs, t_strs = sort_data(t_inps, t_outs, t_strs)\n",
    "t_outs = np.array(t_outs)\n",
    "t_strs = np.array(t_strs)\n",
    "\n",
    "print(\"Train Inps: \", len(inputs))\n",
    "print(\"Train Outs: \", outputs.shape)\n",
    "print(\"Test  Inps: \", len(t_inps))\n",
    "print(\"Test  Outs: \", t_outs.shape)\n",
    "print(\"Labels\\t\",lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##    Model definition + Helper Functions\n",
    "###############################################################################\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, width=3, RF=19):\n",
    "        \"\"\"\n",
    "           Build a stack of 1D convolutions with batch norm and ReLU activations\n",
    "           The final two convolutions are simply linear layers, then followed by\n",
    "           a prediction and attention layer.\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.width = width\n",
    "        self.RF = RF\n",
    "    \n",
    "        self.embedding = nn.Embedding(len(acids), args.hidden_dim)\n",
    "        layers = [\n",
    "          nn.Conv1d(args.hidden_dim, args.hidden_dim, self.width),\n",
    "          nn.ReLU(),\n",
    "          nn.BatchNorm1d(args.hidden_dim),\n",
    "          nn.Conv1d(args.hidden_dim, args.hidden_dim, self.width*2),\n",
    "          nn.ReLU(),\n",
    "          nn.BatchNorm1d(args.hidden_dim),\n",
    "          nn.Conv1d(args.hidden_dim, args.hidden_dim, self.width*4),\n",
    "          nn.ReLU(),\n",
    "          nn.BatchNorm1d(args.hidden_dim),\n",
    "          nn.Conv1d(args.hidden_dim, args.hidden_dim, 1),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv1d(args.hidden_dim, args.hidden_dim, 1),\n",
    "          nn.ReLU(),\n",
    "        ]\n",
    "\n",
    "        self.conv_stack = nn.Sequential(*layers)\n",
    "    \n",
    "        self.pred = nn.Conv1d(args.hidden_dim, num_labels, 1)\n",
    "        self.att = nn.Conv1d(args.hidden_dim, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x).permute(0,2,1)\n",
    "        embed = self.conv_stack(embed)\n",
    "\n",
    "        # Log probabilities for every class at every substring\n",
    "        logits = self.pred(embed)\n",
    "    \n",
    "        # Un-normalized weight of a given n-gram\n",
    "        att = self.att(embed)\n",
    "        # Reshape [b,L] --> [b,1,L]  -- and normalize\n",
    "        re_att = F.softmax(att.view(x.size()[0],1,-1), dim=-1)\n",
    "        # Rescale logits by attention weight\n",
    "        joint = re_att * logits\n",
    "        # Class distribution\n",
    "        collapsed = torch.sum(joint, 2)\n",
    "        return collapsed, att, logits\n",
    "\n",
    "    def reset_counts(self, epoch):\n",
    "        self.gold_counts = np.zeros(num_labels)\n",
    "        self.pred_counts = np.zeros(num_labels)\n",
    "        self.corr_counts = np.zeros(num_labels)\n",
    "        self.epoch = epoch\n",
    "\n",
    "    \"\"\" Helper Functions \"\"\"\n",
    "    def run_evaluation(self, v_inputs, v_outputs, aggregate=False, verbose=False, showTrain=True):\n",
    "        net.train(mode=False)\n",
    "        \"\"\"\n",
    "          Run evaluation\n",
    "        \"\"\"\n",
    "        val_loss = 0.0\n",
    "        val_acc = []\n",
    "        gold_counts = np.zeros(num_labels)\n",
    "        pred_counts = np.zeros(num_labels)\n",
    "        corr_counts = np.zeros(num_labels)\n",
    "\n",
    "        if args.confusion:\n",
    "            pairs = np.zeros((num_labels, num_labels))\n",
    "\n",
    "        v_inps, v_outs = sort_data(v_inputs, v_outputs)\n",
    "        v_outs = np.array(v_outs)\n",
    "        batches = []\n",
    "        indices = list(range(len(v_inps)))\n",
    "        for start in range(0, len(indices), args.batch_size):\n",
    "            batches.append((start, min(args.batch_size, len(indices)-start)))\n",
    "\n",
    "        for start, b_size in tqdm(batches, ncols=80):\n",
    "            vals = indices[start : start + b_size]\n",
    "      \n",
    "            inputs = torch.from_numpy(pad_data(v_inps[indices[start]:indices[start+b_size-1]+1])).to(device)\n",
    "            labels = torch.from_numpy(v_outs[vals]).to(device)\n",
    "            logits, att, full = net(inputs)\n",
    "            att = F.softmax(torch.squeeze(att), dim=-1)\n",
    "            val_loss += F.cross_entropy(logits, labels).item()\n",
    "            _, preds = torch.max(logits, 1)\n",
    "      \n",
    "            preds = preds.data.cpu().numpy()\n",
    "            val_acc.extend(list((preds == v_outs[vals])))\n",
    "      \n",
    "            np.add.at(pred_counts, preds, 1)\n",
    "            np.add.at(gold_counts, v_outs[vals], 1)\n",
    "            np.add.at(corr_counts, preds[(preds == v_outs[vals])], 1)\n",
    "\n",
    "            if args.confusion:\n",
    "                if not args.pconfusion:\n",
    "                    np.add.at(pairs, [v_outs[vals], preds], 1)\n",
    "                else:\n",
    "                    dists = F.softmax(logits, -1)\n",
    "                    for i in range(len(vals)):\n",
    "                        gold = v_outs[vals][i]\n",
    "\n",
    "                        tmp = [(dists[i,j], j) for j in range(len(ilbls))]\n",
    "                        tmp.sort()\n",
    "                        prob, second = tmp[-2]\n",
    "                        pairs[gold, second] += 1\n",
    "\n",
    "            if aggregate:\n",
    "                self.aggregate_predictors(t_strs[vals], v_outs[vals], full, att)\n",
    "\n",
    "        if verbose:\n",
    "            if aggregate or not showTrain:\n",
    "                self.print_eval((gold_counts, pred_counts, corr_counts))\n",
    "            else:\n",
    "                self.print_eval((self.gold_counts, self.pred_counts, self.corr_counts), \n",
    "                               (gold_counts, pred_counts, corr_counts))\n",
    "\n",
    "        if args.confusion:\n",
    "            out = open(\"confusion.csv\", 'w')\n",
    "            out.write(\",\" + \",\".join([ilbls[i] for i in range(len(ilbls))]) + \"\\n\")\n",
    "            for i in range(len(ilbls)):\n",
    "                out.write(\"{},\".format(ilbls[i]))\n",
    "                for j in range(len(ilbls)):\n",
    "                    out.write(\"{},\".format(pairs[i,j]))\n",
    "                out.write(\"\\n\")\n",
    "            out.close()\n",
    "        return val_loss, 100*np.array(val_acc).mean()\n",
    "\n",
    "    def aggregate_predictors(self, seqs, outs, full, att):\n",
    "        dists = F.softmax(full.permute(0, 2, 1), dim=-1)\n",
    "        if dists.shape[0] == 1:\n",
    "            att = att.unsqueeze(0)  # batch size of 1 needs to be unsqueezed\n",
    "        vals = dists * att.unsqueeze(2)\n",
    "        for b in range(len(seqs)):\n",
    "            max_val = -1e10\n",
    "            max_predictor = \"NONE\"\n",
    "            max_class = -1\n",
    "            for i in range(len(att[0])):\n",
    "                predictor = seqs[b][i:i + self.RF]\n",
    "\n",
    "                for c in range(num_labels):\n",
    "                    self.predictors[(predictor, c)] += vals[b,i,c].item() \n",
    "\n",
    "                cval, c = torch.max(vals[b,i,:], 0)\n",
    "                cval = cval.item()\n",
    "                if cval > max_val:\n",
    "                    max_val = cval\n",
    "                    max_predictor = predictor\n",
    "                    max_class = c.item()\n",
    "            self.top_predictor.append((max_val, max_predictor, ilbls[max_class], ilbls[outs[b]], seqs[b].strip()))\n",
    "\n",
    "\n",
    "    def print_predictors(self, epoch):\n",
    "        start = \"nitro\" if args.nitro else \"bd\" if args.bd else \"hco\"\n",
    "        rtype = \"binary\" if args.binary else \"multi\"\n",
    "        rewht = \"reweight\" if args.reweight else \"orig\"\n",
    "        fname = \"{}.{}.{}.{}.{}.h{}.b{}\".format(start, epoch, self.RF, rtype, rewht, args.hidden_dim, args.batch_size)\n",
    "        \n",
    "        g = gzip.open(\"{}.predictors.joint.gz\".format(fname),'wt')\n",
    "        joint = defaultdict(list)\n",
    "        for seq, lbl in self.predictors:\n",
    "            joint[ilbls[lbl]].append((self.predictors[(seq, lbl)], seq))\n",
    "    \n",
    "        for lbl in joint:\n",
    "            vals = joint[lbl]\n",
    "            vals.sort()\n",
    "            vals.reverse()\n",
    "            for val, seq in vals:\n",
    "                g.write(\"{:5} {:30} {}\\n\".format(lbl, seq, val))\n",
    "            g.write(\"\\n\")\n",
    "        g.close()\n",
    "   \n",
    "\n",
    "        g = gzip.open(\"{}.top_predictors.txt.gz\".format(fname), 'wt')\n",
    "        g.write(\"{:10} {:30} {:5} {:5} {}\\n\".format(\"Val\", \"Predictor\", \"Pred\", \"Gold\", \"Seq\"))\n",
    "        self.top_predictor.sort()\n",
    "        self.top_predictor.reverse()\n",
    "        for val, predictor, pred, gold, seq in self.top_predictor:\n",
    "            g.write(\"{:10.9f} {:30} {:5} {:5} {}\\n\".format(val, predictor, pred, gold, seq))\n",
    "        g.close()\n",
    "\n",
    "\n",
    "    def print_eval(self, train, test=None): \n",
    "        \"\"\"  Print training performance  \"\"\"\n",
    "        gold, pred, corr = train\n",
    "        p, r = corr / pred, corr / gold\n",
    "        f = 2*p*r/(p+r)\n",
    "    \n",
    "        if test is not None:\n",
    "            t_gold, t_pred, t_corr = test\n",
    "            t_p, t_r = t_corr / t_pred, t_corr / t_gold\n",
    "            t_f = 2*t_p*t_r/(t_p+t_r)\n",
    "    \n",
    "        gold_counts = [(gold[lab],lab) for lab in range(num_labels)]\n",
    "        gold_counts.sort(reverse=True)\n",
    "        for count, i in gold_counts:\n",
    "            train_str = \"{:<10} {:<5} {:5.3f} {:5.3f} {:5.3f}   \".format(ilbls[i], int(count), p[i], r[i], f[i])\n",
    "            if test is not None:\n",
    "                test_str = \"{:<5} {:5.3f} {:5.3f} {:5.3f}\".format(int(t_gold[i]), t_p[i], t_r[i], t_f[i])\n",
    "            else:\n",
    "                test_str = \"\"\n",
    "            print(train_str + test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 230/230 [00:02<00:00, 103.26it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 424.16it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 98.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.435 0.903 0.588   51    0.411 1.000 0.583\n",
      "C          196   0.346 0.189 0.244   24    0.000 0.000   nan\n",
      "E2         191   0.438 0.037 0.068   29      nan 0.000   nan\n",
      "A          50      nan 0.000   nan   9       nan 0.000   nan\n",
      "E4         40    0.000 0.000   nan   4       nan 0.000   nan\n",
      "E3         30      nan 0.000   nan   5       nan 0.000   nan\n",
      "B          29      nan 0.000   nan   4       nan 0.000   nan\n",
      "Epoch: 0  Train Loss: 351.6937  Acc: 42.31  Val  Loss  41.7535  Acc: 40.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 230/230 [00:02<00:00, 104.66it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 424.23it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 101.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Train Loss: 351.8359  Acc: 42.97  Val  Loss  47.4631  Acc: 40.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.47it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 414.42it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 102.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2  Train Loss: 297.7043  Acc: 52.45  Val  Loss  30.6161  Acc: 62.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.33it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 414.49it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 97.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3  Train Loss: 230.1456  Acc: 62.92  Val  Loss  25.2613  Acc: 72.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.21it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 413.60it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 101.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4  Train Loss: 168.6896  Acc: 72.08  Val  Loss  24.9325  Acc: 73.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.48it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 414.80it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 101.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5  Train Loss: 129.5552  Acc: 79.39  Val  Loss  17.1826  Acc: 81.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.36it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 411.49it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 96.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6  Train Loss: 109.6810  Acc: 80.26  Val  Loss  14.6263  Acc: 80.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 94.93it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 407.61it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 99.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7  Train Loss: 118.3060  Acc: 81.35  Val  Loss  15.5964  Acc: 82.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.55it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 414.99it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 98.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8  Train Loss: 137.5038  Acc: 78.84  Val  Loss  21.7964  Acc: 77.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 230/230 [00:02<00:00, 100.18it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 415.12it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 103.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9  Train Loss:  97.9009  Acc: 83.53  Val  Loss  14.4346  Acc: 83.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.74it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 408.94it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 94.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.807 0.990 0.889   51    0.785 1.000 0.879\n",
      "C          196   1.000 1.000 1.000   24    1.000 1.000 1.000\n",
      "E2         191   0.930 0.628 0.750   29    1.000 0.621 0.766\n",
      "A          50    0.701 0.940 0.803   9     0.692 1.000 0.818\n",
      "E4         40    0.767 0.575 0.657   4     1.000 0.500 0.667\n",
      "E3         30    0.667 0.133 0.222   5     1.000 0.400 0.571\n",
      "B          29    0.682 0.517 0.588   4     1.000 0.500 0.667\n",
      "Epoch: 10  Train Loss:  92.3971  Acc: 85.28  Val  Loss  13.6563  Acc: 85.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 97.95it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 408.89it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 94.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11  Train Loss:  82.2458  Acc: 87.57  Val  Loss  13.2781  Acc: 85.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 95.48it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 409.24it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 96.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12  Train Loss:  89.3924  Acc: 87.57  Val  Loss  12.0231  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.24it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 406.96it/s]\n",
      "  4%|█▋                                         | 9/230 [00:00<00:02, 85.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13  Train Loss:  76.5717  Acc: 88.11  Val  Loss  15.9479  Acc: 85.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 92.20it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 392.62it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 92.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14  Train Loss:  71.5343  Acc: 88.44  Val  Loss  10.0026  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.61it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 405.21it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 97.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15  Train Loss:  74.8080  Acc: 87.46  Val  Loss  12.1250  Acc: 86.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 97.76it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 402.75it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 101.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16  Train Loss:  68.2662  Acc: 89.09  Val  Loss  13.8200  Acc: 85.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 93.98it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 378.76it/s]\n",
      "  4%|█▋                                         | 9/230 [00:00<00:02, 85.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17  Train Loss:  59.1963  Acc: 90.62  Val  Loss  12.3901  Acc: 85.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 96.72it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 409.27it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 95.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18  Train Loss:  58.6792  Acc: 89.86  Val  Loss  13.1723  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.29it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 410.44it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 92.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19  Train Loss:  53.1908  Acc: 90.73  Val  Loss  11.8226  Acc: 88.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.30it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 333.82it/s]\n",
      "  4%|█▋                                         | 9/230 [00:00<00:02, 82.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.842 0.982 0.907   51    0.785 1.000 0.879\n",
      "C          196   0.995 1.000 0.997   24    1.000 1.000 1.000\n",
      "E2         191   0.953 0.634 0.761   29    1.000 0.621 0.766\n",
      "A          50    0.941 0.960 0.950   9     0.818 1.000 0.900\n",
      "E4         40    0.921 0.875 0.897   4     1.000 0.500 0.667\n",
      "E3         30    0.781 0.833 0.806   5     1.000 0.400 0.571\n",
      "B          29    0.964 0.931 0.947   4     1.000 1.000 1.000\n",
      "Epoch: 20  Train Loss:  63.0144  Acc: 90.08  Val  Loss  11.7135  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 95.22it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 405.56it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 100.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21  Train Loss:  55.1405  Acc: 90.08  Val  Loss  11.0607  Acc: 88.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 97.85it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 402.90it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 93.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22  Train Loss:  58.4411  Acc: 90.40  Val  Loss  13.8531  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 93.55it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 403.87it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 97.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23  Train Loss:  52.0512  Acc: 91.17  Val  Loss  12.1972  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 96.68it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 405.92it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 95.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24  Train Loss:  46.1049  Acc: 91.06  Val  Loss  11.7101  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 94.06it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 405.40it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 94.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25  Train Loss:  49.2464  Acc: 91.49  Val  Loss  12.0892  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 96.29it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 335.61it/s]\n",
      "  4%|█▋                                         | 9/230 [00:00<00:02, 78.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26  Train Loss:  50.3017  Acc: 91.28  Val  Loss  13.0061  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 95.67it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 404.92it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 92.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27  Train Loss:  44.9804  Acc: 91.82  Val  Loss  13.8893  Acc: 86.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 95.90it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 404.95it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 95.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28  Train Loss:  74.7633  Acc: 88.44  Val  Loss  16.5958  Acc: 80.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 95.27it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 356.77it/s]\n",
      "  4%|█▋                                         | 9/230 [00:00<00:02, 87.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29  Train Loss:  63.8858  Acc: 89.86  Val  Loss  12.8217  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 94.19it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 336.23it/s]\n",
      "  4%|█▋                                         | 9/230 [00:00<00:02, 84.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.836 0.990 0.906   51    0.794 0.980 0.877\n",
      "C          196   1.000 1.000 1.000   24    1.000 1.000 1.000\n",
      "E2         191   0.992 0.623 0.765   29    1.000 0.586 0.739\n",
      "A          50    0.980 1.000 0.990   9     1.000 1.000 1.000\n",
      "E4         40    1.000 0.950 0.974   4     1.000 1.000 1.000\n",
      "E3         30    0.774 0.800 0.787   5     0.600 0.600 0.600\n",
      "B          29    0.967 1.000 0.983   4     1.000 1.000 1.000\n",
      "Epoch: 30  Train Loss:  51.0776  Acc: 90.84  Val  Loss  12.7071  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 92.32it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 405.40it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 92.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31  Train Loss:  47.2113  Acc: 91.49  Val  Loss  14.7925  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 96.24it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 403.75it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 97.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32  Train Loss:  56.7724  Acc: 89.75  Val  Loss  13.5368  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 94.21it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 376.60it/s]\n",
      "  3%|█▎                                         | 7/230 [00:00<00:03, 69.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33  Train Loss:  47.4792  Acc: 91.38  Val  Loss  11.5993  Acc: 88.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 97.80it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 414.41it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 95.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34  Train Loss:  54.4763  Acc: 90.19  Val  Loss  18.6428  Acc: 84.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.12it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 405.77it/s]\n",
      "  3%|█▍                                         | 8/230 [00:00<00:02, 75.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35  Train Loss:  52.1685  Acc: 90.19  Val  Loss  13.7981  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.51it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 418.87it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 102.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36  Train Loss:  50.5501  Acc: 91.49  Val  Loss  11.5848  Acc: 86.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 230/230 [00:02<00:00, 103.74it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 345.64it/s]\n",
      "  4%|█▋                                         | 9/230 [00:00<00:02, 89.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37  Train Loss:  45.3979  Acc: 91.38  Val  Loss  12.7413  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 94.86it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 405.49it/s]\n",
      "  3%|█▍                                         | 8/230 [00:00<00:02, 74.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38  Train Loss:  48.7109  Acc: 91.71  Val  Loss  14.8596  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 95.68it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 405.11it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 96.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39  Train Loss:  45.0352  Acc: 91.71  Val  Loss  13.1720  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 95.26it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 387.78it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 92.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.844 0.995 0.913   51    0.790 0.961 0.867\n",
      "C          196   1.000 1.000 1.000   24    1.000 1.000 1.000\n",
      "E2         191   0.984 0.628 0.767   29    1.000 0.586 0.739\n",
      "A          50    1.000 1.000 1.000   9     1.000 1.000 1.000\n",
      "E4         40    1.000 1.000 1.000   4     1.000 1.000 1.000\n",
      "E3         30    0.903 0.933 0.918   5     0.500 0.600 0.545\n",
      "B          29    1.000 1.000 1.000   4     1.000 1.000 1.000\n",
      "Epoch: 40  Train Loss:  45.6499  Acc: 91.82  Val  Loss  14.0875  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 95.24it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 402.03it/s]\n",
      "  3%|█▍                                         | 8/230 [00:00<00:03, 72.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41  Train Loss:  42.2553  Acc: 92.26  Val  Loss  13.9212  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 95.40it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 388.09it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 92.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42  Train Loss:  43.5909  Acc: 91.82  Val  Loss  13.7082  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 94.99it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 383.58it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 91.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43  Train Loss:  42.3970  Acc: 91.71  Val  Loss  14.0716  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 94.97it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.87it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 91.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44  Train Loss:  42.8070  Acc: 92.15  Val  Loss  13.9324  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 93.60it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.47it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 100.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45  Train Loss:  39.5999  Acc: 92.37  Val  Loss  15.8031  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 94.85it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 401.36it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 93.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46  Train Loss:  39.4160  Acc: 92.15  Val  Loss  17.9956  Acc: 84.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 96.57it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 401.10it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 92.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47  Train Loss:  39.4920  Acc: 92.26  Val  Loss  21.6190  Acc: 85.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 93.55it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 404.74it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 96.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48  Train Loss:  54.6131  Acc: 90.40  Val  Loss  24.3596  Acc: 80.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 96.90it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 410.81it/s]\n",
      "  3%|█▍                                         | 8/230 [00:00<00:02, 79.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49  Train Loss:  74.4202  Acc: 88.99  Val  Loss  12.6518  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 92.34it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 390.77it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 91.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.847 0.984 0.910   51    0.794 0.980 0.877\n",
      "C          196   1.000 1.000 1.000   24    1.000 0.958 0.979\n",
      "E2         191   0.946 0.639 0.763   29    0.944 0.586 0.723\n",
      "A          50    0.943 1.000 0.971   9     0.857 0.667 0.750\n",
      "E4         40    1.000 0.925 0.961   4     0.667 1.000 0.800\n",
      "E3         30    0.967 0.967 0.967   5     0.600 0.600 0.600\n",
      "B          29    0.966 0.966 0.966   4     1.000 1.000 1.000\n",
      "Epoch: 50  Train Loss:  46.5269  Acc: 91.28  Val  Loss  20.4195  Acc: 84.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 94.41it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 391.00it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 95.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51  Train Loss:  43.6249  Acc: 91.82  Val  Loss  16.9270  Acc: 83.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.41it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 395.45it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 96.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52  Train Loss:  48.2115  Acc: 91.38  Val  Loss  17.1226  Acc: 86.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 97.82it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 396.75it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 96.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53  Train Loss:  52.1099  Acc: 90.62  Val  Loss  11.7068  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.68it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 391.02it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 102.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54  Train Loss:  41.0947  Acc: 92.15  Val  Loss  15.2109  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.99it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 395.48it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 96.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55  Train Loss:  40.5131  Acc: 92.04  Val  Loss  17.3064  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.20it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 396.86it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 91.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56  Train Loss:  42.1254  Acc: 92.04  Val  Loss  19.7508  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.01it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 395.99it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 100.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57  Train Loss:  55.3191  Acc: 90.29  Val  Loss  22.3505  Acc: 84.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.90it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 397.04it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 98.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58  Train Loss:  56.4221  Acc: 90.19  Val  Loss  14.3542  Acc: 86.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.69it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 383.02it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 98.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59  Train Loss:  40.8963  Acc: 92.04  Val  Loss  17.6879  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.29it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 401.28it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 101.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.850 0.984 0.912   51    0.794 0.980 0.877\n",
      "C          196   1.000 1.000 1.000   24    1.000 1.000 1.000\n",
      "E2         191   0.955 0.660 0.780   29    1.000 0.586 0.739\n",
      "A          50    1.000 1.000 1.000   9     1.000 0.889 0.941\n",
      "E4         40    1.000 1.000 1.000   4     0.800 1.000 0.889\n",
      "E3         30    1.000 0.967 0.983   5     0.600 0.600 0.600\n",
      "B          29    1.000 1.000 1.000   4     1.000 1.000 1.000\n",
      "Epoch: 60  Train Loss:  39.1661  Acc: 92.15  Val  Loss  20.3898  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.39it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.18it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 97.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61  Train Loss:  37.8939  Acc: 92.48  Val  Loss  22.8687  Acc: 83.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.36it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 390.40it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 95.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62  Train Loss:  62.8160  Acc: 90.29  Val  Loss  17.7594  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.06it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 397.01it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 98.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63  Train Loss:  41.9512  Acc: 90.95  Val  Loss  17.3506  Acc: 86.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.31it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 401.03it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 99.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64  Train Loss:  37.8037  Acc: 91.93  Val  Loss  23.2685  Acc: 83.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.18it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 399.13it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 101.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65  Train Loss:  38.0569  Acc: 92.37  Val  Loss  23.5975  Acc: 84.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.69it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.29it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 100.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66  Train Loss:  36.7571  Acc: 92.58  Val  Loss  27.7459  Acc: 86.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.62it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.30it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 99.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67  Train Loss:  40.2561  Acc: 92.37  Val  Loss  22.2136  Acc: 84.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.91it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.72it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 94.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68  Train Loss:  59.0180  Acc: 92.26  Val  Loss  17.4901  Acc: 77.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.68it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.27it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 99.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69  Train Loss:  77.9812  Acc: 87.79  Val  Loss  19.0284  Acc: 86.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 94.51it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 396.65it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 98.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.844 0.979 0.906   51    0.790 0.961 0.867\n",
      "C          196   1.000 1.000 1.000   24    1.000 0.958 0.979\n",
      "E2         191   0.946 0.644 0.766   29    0.947 0.621 0.750\n",
      "A          50    1.000 0.980 0.990   9     0.900 1.000 0.947\n",
      "E4         40    1.000 0.975 0.987   4     1.000 1.000 1.000\n",
      "E3         30    0.867 0.867 0.867   5     0.750 0.600 0.667\n",
      "B          29    0.935 1.000 0.967   4     1.000 1.000 1.000\n",
      "Epoch: 70  Train Loss:  50.0145  Acc: 91.06  Val  Loss  13.5440  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.02it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.38it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 93.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71  Train Loss:  43.2364  Acc: 91.60  Val  Loss  15.4075  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.66it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 387.44it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 95.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72  Train Loss:  44.5184  Acc: 92.37  Val  Loss  16.7557  Acc: 85.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.33it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.30it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 94.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73  Train Loss:  40.7995  Acc: 92.69  Val  Loss  17.5070  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.28it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.36it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 94.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74  Train Loss:  38.4228  Acc: 92.58  Val  Loss  16.9688  Acc: 82.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.35it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 397.38it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 97.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75  Train Loss:  36.0859  Acc: 92.80  Val  Loss  18.7799  Acc: 81.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.11it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 396.04it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 94.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76  Train Loss:  42.7765  Acc: 92.37  Val  Loss  16.6080  Acc: 87.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.57it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 395.87it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 98.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77  Train Loss:  41.7964  Acc: 91.71  Val  Loss  14.8392  Acc: 84.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.74it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 394.35it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 95.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78  Train Loss:  35.1415  Acc: 92.91  Val  Loss  16.8591  Acc: 82.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 97.64it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 389.55it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 97.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79  Train Loss:  36.6975  Acc: 92.48  Val  Loss  17.3579  Acc: 86.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.77it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.31it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 91.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.868 0.963 0.913   51    0.780 0.902 0.836\n",
      "C          196   1.000 1.000 1.000   24    1.000 1.000 1.000\n",
      "E2         191   0.907 0.712 0.798   29    0.810 0.586 0.680\n",
      "A          50    1.000 1.000 1.000   9     1.000 1.000 1.000\n",
      "E4         40    1.000 1.000 1.000   4     1.000 1.000 1.000\n",
      "E3         30    1.000 0.967 0.983   5     0.600 0.600 0.600\n",
      "B          29    1.000 1.000 1.000   4     1.000 1.000 1.000\n",
      "Epoch: 80  Train Loss:  35.4012  Acc: 92.37  Val  Loss  19.4988  Acc: 84.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.43it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.26it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 99.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81  Train Loss:  34.2410  Acc: 93.02  Val  Loss  20.3654  Acc: 83.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.54it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 401.03it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 97.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82  Train Loss:  34.9866  Acc: 93.24  Val  Loss  23.4253  Acc: 81.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.44it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.44it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 94.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83  Train Loss:  41.9792  Acc: 92.69  Val  Loss  19.3788  Acc: 82.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.52it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 399.90it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 94.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84  Train Loss:  57.3513  Acc: 90.51  Val  Loss  17.2207  Acc: 88.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.59it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 395.47it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 100.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85  Train Loss:  40.5956  Acc: 92.58  Val  Loss  20.0509  Acc: 83.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.93it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 395.52it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 99.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86  Train Loss:  39.9764  Acc: 92.48  Val  Loss  21.9595  Acc: 82.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.66it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 397.43it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 99.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87  Train Loss:  35.2111  Acc: 92.04  Val  Loss  22.5451  Acc: 81.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.72it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 397.13it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 100.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88  Train Loss:  34.2456  Acc: 92.69  Val  Loss  24.4835  Acc: 82.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.02it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 396.65it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 101.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89  Train Loss:  35.4413  Acc: 92.58  Val  Loss  21.9715  Acc: 82.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.80it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 399.51it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 94.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.889 0.945 0.916   51    0.755 0.784 0.769\n",
      "C          196   1.000 1.000 1.000   24    1.000 1.000 1.000\n",
      "E2         191   0.874 0.764 0.816   29    0.654 0.586 0.618\n",
      "A          50    1.000 1.000 1.000   9     1.000 1.000 1.000\n",
      "E4         40    1.000 1.000 1.000   4     1.000 1.000 1.000\n",
      "E3         30    1.000 1.000 1.000   5     0.500 0.600 0.545\n",
      "B          29    1.000 1.000 1.000   4     1.000 1.000 1.000\n",
      "Epoch: 90  Train Loss:  32.1505  Acc: 92.80  Val  Loss  27.6306  Acc: 80.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.35it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 395.76it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 93.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91  Train Loss:  31.5257  Acc: 93.89  Val  Loss  28.7773  Acc: 81.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.83it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 396.18it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 98.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92  Train Loss:  29.5811  Acc: 93.78  Val  Loss  28.0461  Acc: 82.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.84it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.68it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 98.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93  Train Loss:  33.1319  Acc: 93.02  Val  Loss  23.3745  Acc: 86.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.45it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 399.93it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 99.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94  Train Loss:  46.9704  Acc: 91.93  Val  Loss  22.9814  Acc: 80.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.95it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.57it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 100.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95  Train Loss:  37.1493  Acc: 91.93  Val  Loss  21.8564  Acc: 73.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 99.73it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 399.89it/s]\n",
      "  5%|█▉                                       | 11/230 [00:00<00:02, 101.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96  Train Loss:  30.0833  Acc: 93.57  Val  Loss  26.0779  Acc: 73.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.64it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 400.04it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 98.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97  Train Loss:  73.9975  Acc: 89.75  Val  Loss  21.6816  Acc: 76.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 97.97it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 396.13it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 99.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98  Train Loss:  47.2879  Acc: 92.04  Val  Loss  18.6658  Acc: 79.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.55it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 395.71it/s]\n",
      "  4%|█▊                                        | 10/230 [00:00<00:02, 97.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99  Train Loss:  32.9506  Acc: 93.02  Val  Loss  22.2640  Acc: 82.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:02<00:00, 98.46it/s]\n",
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 396.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.897 0.958 0.926   51    0.778 0.824 0.800\n",
      "C          196   1.000 1.000 1.000   24    1.000 1.000 1.000\n",
      "E2         191   0.903 0.780 0.837   29    0.654 0.586 0.618\n",
      "A          50    0.980 1.000 0.990   9     1.000 1.000 1.000\n",
      "E4         40    1.000 0.950 0.974   4     1.000 1.000 1.000\n",
      "E3         30    1.000 1.000 1.000   5     0.600 0.600 0.600\n",
      "B          29    0.967 1.000 0.983   4     1.000 1.000 1.000\n",
      "Epoch: 100  Train Loss:  29.8386  Acc: 93.46  Val  Loss  23.1621  Acc: 81.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "##    Training Loop\n",
    "###############################################################################\n",
    "#torch.cuda.manual_seed(20180119)  <-- set a value for consistency\n",
    "if args.load != '':\n",
    "    net = torch.load(args.load)                             # Load Saved Model\n",
    "    net.to(device)\n",
    "    if args.confusion:\n",
    "        loss, acc = net.run_evaluation(t_inps, t_outs, aggregate=args.load_test != '')\n",
    "    else:\n",
    "        loss, acc = net.run_evaluation(t_inps, t_outs, aggregate=args.load_test != '')\n",
    "    print(\"Acc: {:5.3f}\".format(acc))\n",
    "    if args.load_test != '':\n",
    "        net.print_predictors(\"test\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    net = Net()\n",
    "    net.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "\n",
    "\"\"\"\n",
    "  Perform training\n",
    "\"\"\"\n",
    "prev_acc = 0\n",
    "for epoch in range(0, args.epochs + 1):\n",
    "    net.predictors = defaultdict(int)\n",
    "    net.top_predictor = []\n",
    "\n",
    "    batches = []\n",
    "    indices = list(range(len(inps)))\n",
    "    for start in range(0, len(indices), args.batch_size):\n",
    "        batches.append((start, min(args.batch_size, len(indices)-start)))\n",
    "    random.shuffle(batches)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    train_acc = []\n",
    "  \n",
    "    net.reset_counts(epoch)\n",
    "    for start, b_size in tqdm(batches, ncols=80):\n",
    "        r = indices[start : start + b_size]\n",
    "        \n",
    "        # Setup\n",
    "        optimizer.zero_grad()\n",
    "        inputs = torch.from_numpy(pad_data(inps[indices[start] : indices[start+b_size-1] + 1])).to(device)\n",
    "        labels = torch.from_numpy(outs[r]).to(device)\n",
    "\n",
    "        # Predict\n",
    "        net.train(mode=True)\n",
    "        logits, att, full = net(inputs)\n",
    "        if args.reweight:\n",
    "            ce_loss = F.cross_entropy(logits, labels, weight=weight)\n",
    "        else:\n",
    "            ce_loss = F.cross_entropy(logits, labels)\n",
    "        att = F.softmax(torch.squeeze(att), dim=-1)\n",
    "    \n",
    "        # Compute loss and update\n",
    "        loss = ce_loss\n",
    "        total_loss += ce_loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Look at predictions\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        dists = full.permute(0,2,1).cpu().data.numpy()\n",
    "    \n",
    "        preds = preds.data.cpu().numpy()\n",
    "        np.add.at(net.pred_counts, preds, 1)\n",
    "        np.add.at(net.gold_counts, outs[r], 1)\n",
    "        np.add.at(net.corr_counts, preds[preds == outs[r]], 1)\n",
    "\n",
    "        train_acc.extend(list(preds == outs[r]))\n",
    "  \n",
    "    # Evaluate on validation (during training)\n",
    "    val_loss, val_acc = net.run_evaluation(t_inps, t_outs, verbose=(epoch % 10 == 0 or epoch == args.epochs))\n",
    "\n",
    "    print(\"Epoch: {}  Train Loss: {:8.4f}  Acc: {:5.2f}  Val  Loss {:8.4f}  Acc: {:5.2f}\".format(epoch, \n",
    "          total_loss, 100*np.array(train_acc).mean(), val_loss, val_acc))\n",
    "\n",
    "    # Save best validation model for optimal generalization\n",
    "    if val_acc > prev_acc:\n",
    "        prev_acc = val_acc\n",
    "        pref = \"nitro\" if args.nitro else \"bd\" if args.bd else \"hco\"\n",
    "        torch.save(net, \"{}.{}.model\".format(pref, run))\n",
    "\n",
    "out = torch.cat((net.embedding.weight.data, torch.ones(len(acids), 1).to(device)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is an example run of 100 epochs with training (left) and validation (right) precision, recall and F1 printed for every class.  Additionally, we print the overall  losses and accuracies after every epoch.  Note, these do not decrease monitonically but in general the model does perform better after some backtracking.  For most use cases a  shorter training regime is probably sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [01:18<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         381   0.842 0.990 0.910   \n",
      "C          196   0.995 1.000 0.997   \n",
      "E2         191   0.992 0.623 0.765   \n",
      "A          50    1.000 0.960 0.980   \n",
      "E4         40    1.000 1.000 1.000   \n",
      "E3         30    0.771 0.900 0.831   \n",
      "B          29    1.000 1.000 1.000   \n",
      "Acc: 91.167\n"
     ]
    }
   ],
   "source": [
    "args.load = \"bd.multi.e100.h256.b4.model\"\n",
    "net = torch.load(args.load)                             # Load Saved Model\n",
    "net.to(device)\n",
    "\n",
    "# Run evaluation with best validation model on training\n",
    "val = [line.strip().split() for line in open(DATA_DIR + prefix + \".train\",'r')]\n",
    "t_strs = np.array([sequence for label, sequence in val])\n",
    "t_inps = [to_int(sequence) for label, sequence in val]\n",
    "t_outs = np.array([lbls[label] for label, sequence in val])\n",
    "args.confusion = True\n",
    "args.pconfusion = False\n",
    "loss, acc = net.run_evaluation(t_inps, t_outs, aggregate=True, verbose=True)\n",
    "net.print_predictors(\"final\")\n",
    "print(\"Acc: {:5.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print confusion matrix on training data\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = [line.strip().replace(\"[\",\"\").replace(\"]\",\"\").split(\",\") for line in open(\"confusion.csv\")]\n",
    "labels = data[0][1:]\n",
    "data = [[float(v) for v in line[1:-1]] for line in data[1:]]\n",
    "df = pd.DataFrame(data, index = [i for i in labels], columns = [i for i in labels])\n",
    "df_norm_col = df.div(df.sum(axis=1), axis=0)\n",
    "plt.figure(figsize = (10,7))\n",
    "_ = sn.heatmap(df_norm_col, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 32/32 [00:00<00:00, 301.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         51    0.785 1.000 0.879   \n",
      "E2         29    1.000 0.621 0.766   \n",
      "C          24    1.000 1.000 1.000   \n",
      "A          9     1.000 1.000 1.000   \n",
      "E3         5     1.000 0.400 0.571   \n",
      "B          4     1.000 1.000 1.000   \n",
      "E4         4     1.000 1.000 1.000   \n",
      "Acc: 88.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation with best validation model on validation\n",
    "val = [line.strip().split() for line in open(DATA_DIR + prefix + \".val\",'r')]\n",
    "t_strs = np.array([sequence for label, sequence in val])\n",
    "t_inps = [to_int(sequence) for label, sequence in val]\n",
    "t_outs = np.array([lbls[label] for label, sequence in val])\n",
    "args.confusion = True\n",
    "args.pconfusion = False\n",
    "loss, acc = net.run_evaluation(t_inps, t_outs, showTrain=False, verbose=True)\n",
    "print(\"Acc: {:5.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 69/69 [00:00<00:00, 352.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1         117   0.865 0.983 0.920   \n",
      "C          61    1.000 1.000 1.000   \n",
      "E2         52    0.972 0.673 0.795   \n",
      "A          15    0.938 1.000 0.968   \n",
      "E3         11    0.700 0.636 0.667   \n",
      "E4         9     0.889 0.889 0.889   \n",
      "B          8     1.000 1.000 1.000   \n",
      "Acc: 91.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation with best validation model on test\n",
    "val = [line.strip().split() for line in open(DATA_DIR + prefix + \".test\",'r')]\n",
    "t_strs = np.array([sequence for label, sequence in val])\n",
    "t_inps = [to_int(sequence) for label, sequence in val]\n",
    "t_outs = np.array([lbls[label] for label, sequence in val])\n",
    "loss, acc = net.run_evaluation(t_inps, t_outs, showTrain=False, verbose=True)\n",
    "print(\"Acc: {:5.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
